\PassOptionsToPackage{svgnames,dvipsnames}{xcolor}

\documentclass[12pt]{cmuthesis}

\usepackage[Lenny]{fncychap}
\ChNameVar{\Large}

\input{packages}
\input{macros}

% \draftstamp{\today}{DRAFT}

\begin {document}
\frontmatter

\pagestyle{empty}

\title{{\bf Planning and Execution using Inaccurate Models with
    Provable Guarantees on Task Completeness}}
\author{Anirudh Vemula}
\date{Oct 2020}
\Year{2020}
%\trnumber{CMU-CS-19-109}

\committee{
  Maxim Likhachev, Co-Chair \\
  J. Andrew Bagnell, Co-Chair \\
  Oliver Kroemer \\
  Leslie Pack Kaelbling (MIT)
%   \begin{tabular}{cc}
%     & \\
% Maxim Likhachev, Co-Chair & CMU\\
% J. Andrew Bagnell, Co-Chair & CMU\\
%     Oliver Kroemer & CMU \\
%     Leslie Pack Kaelbling & MIT
% \end{tabular}
}

\support{}
\disclaimer{}

\keywords{Planning, Reinforcement Learning, Manipulation, Optimization}

\maketitle

% \begin{dedication}
%   To all of the people that light up my life. {\ensuremath\heartsuit}
% \end{dedication}

\begin{abstract}
  Modern planning methods are effective in computing feasible and
optimal plans for robotic tasks when given access to accurate
dynamical models.
However, robots operating in the real
world often face situations that cannot be modeled perfectly before
execution.
Thus, we only have access to simplified but potentially inaccurate 
models.
This imperfect modeling can lead to highly suboptimal plans
or even the inability to reach the goal during execution.
Existing approaches present a learning-based solution where real-world
experience is used to learn a complex dynamical model that is
subsequently used for planning. However, this requires a prohibitively
large amount of experience over the entire state space, and can
be wasteful if we are interested in completing the task and not in
modeling the dynamics accurately. Furthermore, real robots often have
operating constraints and cannot spend hours acquiring experience to
learn dynamics.
% Furthermore, for domains where
% modeling the true dynamics is intractable such as deformable
% manipulation, or vary over time due to 
% wear and tear, the learned model can still end up being inaccurate.
% This thesis argues that using a simplified and potentially inaccurate model for
% planning allows us to significantly reduce the amount of real-world
% experience needed to provably guarantee that the robot completes the
% task.
This thesis argues that by updating the behavior of the planner and
not the dynamics of the model, we can
leverage simplified and potentially inaccurate models and
significantly reduce the amount of real-world experience needed to
provably guarantee that the robot completes the task.

In completed work, we proposed two approaches in support of this
argument. The first approach \cmax{} guarantees that the robot reaches the
goal using the inaccurate model without any resets. This
is achieved by biasing the planner away from transitions whose
dynamics are discovered to be inaccurately modeled during online
execution. However, \cmax{} requires strong assumptions on the
accuracy of the model used for planning and fails to improve the
quality of solution over repetitions of the same task. The second
approach \cmaxpp{} leverages real-world experience to improve the
quality of resulting plans over successive repetitions of a robotic
task. \cmaxpp{} achieves this by integrating model-free learning using
acquired experience with model-based planning using the potentially
inaccurate model. As a consequence of this in addition to completeness, \cmaxpp{} also
guarantees asymptotic convergence to the optimal path cost
as the number of repetitions increases under relaxed
assumptions. Crucially, both approaches do not require any updates to
the dynamics of the model unlike any existing method for planning
using inaccurate models.

For the remainder of the thesis, we propose to combine the advantages
of existing methods that update the dynamics of the model and our
methods that update the behavior of the
planner. The goal is to create a unified
framework where the robot, during the course of its execution,
intelligently switches between (a) learning the true dynamics, (b)
learning a model-free value estimate, or (c)
biasing the planner away from an inaccurately modeled
transition to guarantee task completeness while reducing
the amount of real-world experience required. Additionally, we also
want to explore this unified framework in the episodic setting, where
the robot has access to resets, and in settings where the dynamics are
nondeterministic.
\end{abstract}

% \newgeometry{left=0.5in,right=0.5in,top=1in,bottom=1.4in}
% \begin{acknowledgments}
% \end{acknowledgments}
% \restoregeometry

\pagestyle{plain}

\tableofcontents
\addtocontents{toc}{\vspace*{-2cm}}
\listoffigures
\addtocontents{lof}{\vspace*{-2cm}}
\listoftables
\listofalgorithms

\mainmatter

\input{chapters/introduction}
%\input{chapters/background}
%\input{chapters/related-work}
\input{chapters/aistats19}
\input{chapters/cmax}
\input{chapters/cmaxpp}
\input{chapters/proposed-work}

\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}

\vspace{-25mm}
This bibliography contains \total{citenum} references.
\vspace{10mm}

\printbibliography[heading=none]

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
